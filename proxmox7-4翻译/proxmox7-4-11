proxmox7-4-11

第11章
Proxmox容器工具包
容器是与完全虚拟化的机器（VM）相比较轻量级的替代方案。它们使用它们运行在其上的主机系统的内核，而不是模拟一个完整的操作系统（OS）。
这意味着容器可以直接访问主机系统上的资源。
容器的运行成本很低，通常可以忽略不计。然而，有一些需要考虑的缺点：
• Proxmox容器中只能运行Linux发行版。在容器内部无法运行其他操作系统，例如FreeBSD或Microsoft Windows。
• 出于安全原因，需要限制对主机资源的访问。因此，容器在它们自己的独立命名空间中运行。此外，一些系统调用（用户空间对Linux内核的请求）在容器内不允许。
Proxmox VE 使用 Linux 容器（LXC）作为其底层容器技术。 “Proxmox容器工具包”（pct）通过提供一个抽象复杂任务的接口，简化了LXC的使用和管理。
容器与Proxmox VE紧密集成。这意味着它们知道集群设置，并且可以像虚拟机一样使用相同的网络和存储资源。您还可以使用Proxmox VE防火墙或使用HA框架管理容器。
我们的主要目标是提供一个环境，提供使用VM的好处，但不需要额外的开销。这意味着Proxmox容器可以被归类为“系统容器”，而不是“应用程序容器”。
注意
如果您想运行应用程序容器，例如Docker镜像，建议您在Proxmox QEMU 
VM中运行它们。这将为您提供所有应用程序容器化的优势，同时还提供VM提供的好处，如与主机的强隔离和实时迁移能力，这在容器中否则无法实现。

11.1 技术概述
• LXC（https://linuxcontainers.org/）
• 集成到 Proxmox VE 图形化 Web 用户界面（GUI）
• 易于使用的命令行工具pct
• 通过 Proxmox VE REST API 访问
• lxcfs 提供容器化的 /proc 文件系统
• 控制组（cgroups）用于资源隔离和限制
• 使用 AppArmor 和 seccomp 提高安全性
• 现代 Linux 内核
• 基于镜像的部署（模板 第11.2节）
• 使用 Proxmox VE 存储库第7章
• 从主机进行容器设置（网络，DNS，存储等）

11.2 支持的发行版
下面是官方支持的发行版列表。
以下发行版的模板可以通过我们的存储库获得。您可以使用pveam 第11.3节工具或图形用户界面下载它们。

11.2.1 Alpine Linux
Alpine Linux 是基于 musl libc 和 busybox 的安全导向的轻量级 Linux 发行版。
    https://alpinelinux.org
    有关当前支持的版本，请参见：
    https://alpinelinux.org/releases/
    11.2.2 Arch Linux
    Arch Linux，一款轻量级且灵活的 Linux® 发行版，试图保持简单。
    https://archlinux.org/
    Arch Linux 使用滚动发布模型，有关更多详细信息，请参阅其维基：
    https://wiki.archlinux.org/title/Arch_Linux

11.2.3 CentOS、Almalinux、Rocky Linux
CentOS / CentOS Stream
CentOS Linux 发行版是一个稳定、可预测、可管理和可复制的平台，源自 Red Hat Enterprise Linux（RHEL）的源代码。
    https://centos.org
    有关当前支持的版本，请参见：
    https://wiki.centos.org/About/Product
    Almalinux
    一个开源、社区拥有和管理的永久免费企业级 Linux 发行版，专注于长期稳定性，提供一个强大的生产级平台。AlmaLinux OS 与 RHEL® 和预先配置的 CentOS 具有 1:1 二进制兼容性。
    https://almalinux.org
    有关当前支持的版本，请参见：
    https://en.wikipedia.org/wiki/AlmaLinux#Releases
    Rocky Linux
    Rocky Linux 是一个社区企业操作系统，旨在与美国顶级企业级 Linux 发行版实现 100% 缺陷兼容，现在其下游合作伙伴已经改变方向。
    https://rockylinux.org
    有关当前支持的版本，请参见：
    https://en.wikipedia.org/wiki/Rocky_Linux#Releases

11.2.4 Debian
    Debian 是一个免费的操作系统，由 Debian 项目开发和维护。一个免费的 Linux 发行版，拥有数千个应用程序，以满足我们用户的需求。
    https://www.debian.org/intro/index#software
    有关当前支持的版本，请参见：
    https://www.debian.org/releases/stable/releasenotes

11.2.5 Devuan
Devuan GNU+Linux 是 Debian 的一个没有 systemd 的分支，允许用户通过避免不必要的纠缠并确保 Init Freedom 来重新控制他们的系统。
    https://www.devuan.org
    有关当前支持的版本，请参见：
    https://www.devuan.org/os/releases
    
11.2.6 Fedora
    Fedora 为硬件、云和容器创建了一个创新的、免费的、开源平台，使软件开发人员和社区成员能够为他们的用户构建定制解决方案。
    https://getfedora.org
    有关当前支持的版本，请参见：
    https://fedoraproject.org/wiki/Releases

11.2.7 Gentoo
    高度灵活的基于源代码的 Linux 发行版。
    https://www.gentoo.org
    Gentoo 使用滚动发布模型。

11.2.8 OpenSUSE
    系统管理员、开发人员和桌面用户的首选。
    https://www.opensuse.org
    有关当前支持的版本，请参见：
    https://get.opensuse.org/leap/

11.2.9 Ubuntu
    Ubuntu 是适用于企业服务器、桌面、云和物联网的现代、开源的 Linux 操作系统。
    https://ubuntu.com/
    有关当前支持的版本，请参见：
    https://wiki.ubuntu.com/Releases

11.3 容器镜像
容器镜像有时也被称为“模板”或“应用程序”，它们是包含运行容器所需的一切的 tar 归档文件。
Proxmox VE 本身为最常见的 Linux 发行版（第 11.2 节）提供了各种基本模板。它们可以使用 GUI 或 pveam（Proxmox VE Appliance Manager 
的缩写）命令行实用程序下载。此外，还可以下载 TurnKey Linux 容器模板。
通过 pve-daily-update 计时器，可用模板列表每天更新一次。您还可以通过执行以下命令手动触发更新：
pveam update
要查看可用镜像列表，请运行：
pveam available
您可以通过指定感兴趣的部分来限制此大型列表，例如基本系统镜像：
列出可用的系统镜像
# pveam available --section system
system alpine-3.12-default_20200823_amd64.tar.xz
system alpine-3.13-default_20210419_amd64.tar.xz
system alpine-3.14-default_20210623_amd64.tar.xz
system archlinux-base_20210420-1_amd64.tar.gz
system centos-7-default_20190926_amd64.tar.xz
system centos-8-default_20201210_amd64.tar.xz
system debian-9.0-standard_9.7-1_amd64.tar.gz
system debian-10-standard_10.7-1_amd64.tar.gz
system devuan-3.0-standard_3.0_amd64.tar.gz
system fedora-33-default_20201115_amd64.tar.xz
system fedora-34-default_20210427_amd64.tar.xz
system gentoo-current-default_20200310_amd64.tar.xz
system opensuse-15.2-default_20200824_amd64.tar.xz
system ubuntu-16.04-standard_16.04.5-1_amd64.tar.gz
system ubuntu-18.04-standard_18.04.1-1_amd64.tar.gz
system ubuntu-20.04-standard_20.04-1_amd64.tar.gz
system ubuntu-20.10-standard_20.10-1_amd64.tar.gz
system ubuntu-21.04-standard_21.04-1_amd64.tar.gz
在使用这样的模板之前，您需要将它们下载到您的存储中。如果您不确定要下载到哪个存储，可以简单地使用名为 local 的存储。
对于集群安装，建议使用共享存储，以便所有节点都可以访问这些镜像。
pveam download local debian-10.0-standard_10.0-1_amd64.tar.gz
现在您已经准备好使用该镜像创建容器，您可以使用以下命令列出存储 local 上的所有已下载镜像：
# pveam list local
local:vztmpl/debian-10.0-standard_10.0-1_amd64.tar.gz 219.95MB
提示
您还可以使用 Proxmox VE Web 界面 GUI 下载、列出和删除容器模板。
pct 使用它们来创建一个新容器，例如：
pct create 999 local:vztmpl/debian-10.0-standard_10.0-1_amd64.tar.gz
上面的命令显示了完整的 Proxmox VE 卷标识符。它们包括存储名称，而且大多数其他 Proxmox VE 命令都可以使用它们。例如，您可以稍后使用以下命令删除该镜像：
pveam remove local:vztmpl/debian-10.0-standard_10.0-1_amd64.tar.gz

11.4 容器设置

11.4.1 一般设置
容器的一般设置包括：
• 节点：运行容器的物理服务器
• CT ID：在此 Proxmox VE 安装中用于标识容器的唯一编号
• 主机名：容器的主机名
• 资源池：容器和虚拟机的逻辑组
• 密码：容器的 root 密码
• SSH 公钥：用于通过 SSH 连接到 root 帐户的公钥
• 非特权容器：此选项允许在创建时选择是否要创建特权或非特权容器。
非特权容器
非特权容器使用一种名为用户命名空间的新内核功能。容器内的 root UID 0 
映射到容器外的非特权用户。这意味着这些容器中的大多数安全问题（容器逃逸、资源滥用等）将影响随机的非特权用户，并将成为一般内核安全漏洞而非 LXC 问题。
LXC 团队认为非特权容器在设计上是安全的。
这是创建新容器时的默认选项。
注意
如果容器使用 systemd 作为 init 系统，请注意容器内运行的 systemd 版本应等于或大于 220。
特权容器
容器中的安全性是通过使用强制访问控制 AppArmor 限制、seccomp 过滤器和 Linux 内核命名空间来实现的。
LXC 团队认为这种容器是不安全的，他们不会认为新的容器逃逸漏洞是值得 CVE 和快速修复的安全问题。这就是为什么特权容器只应在受信任的环境中使用。

11.4.2 CPU
您可以使用 cores 选项限制容器内可见的 CPU 数量。这是通过使用 Linux cpuset cgroup（控制组）来实现的。pvestatd 中的一个特殊任务会定期尝试在可用 CPU 
之间分配运行中的容器。要查看分配的 CPU，请运行以下命令：
# pct cpusets
---------------------
102: 6 7
105: 2 3 4 5
108: 0 1
---------------------
容器直接使用主机内核。容器内的所有任务都由主机 CPU 调度程序处理。
Proxmox VE 默认使用 Linux CFS（完全公平调度程序）调度程序，该调度程序具有额外的带宽控制选项。
cpulimit：您可以使用此选项进一步限制分配的 CPU 时间。请注意，这是一个浮点数，因此将两个内核分配给容器但将整体 CPU 消耗限制在半个内核是完全有效的。
cores：2
cpulimit：0.5
cpuunits：这是传递给内核调度程序的相对权重。数字越大，此容器获得的 CPU 时间越多。数字与所有其他运行容器的权重相关。
默认值为 100（如果主机使用传统的 cgroup v1，则为 1024）。
您可以使用此设置优先考虑某些容器。

11.4.3 内存
容器内存使用 cgroup 内存控制器进行控制。
memory：限制整体内存使用。这对应于 memory.limit_in_bytes cgroup 设置。
swap：允许容器从主机交换空间使用额外的交换内存。这对应于 memory.memsw.limit_in_bytes cgroup 设置，该设置设置为两个值（内存 + 交换）之和。

11.4.4 挂载点
根挂载点使用 rootfs 属性进行配置。您可以配置多达 256 个其他挂载点。相应的选项称为 mp0 到 mp255。它们可以包含以下设置：
rootfs: [volume=]<volume> [,acl=<1|0>]
[,mountoptions=<opt[;opt...]>] [,quota=<1|0>] [,replicate=<1|0>]
[,ro=<1|0>] [,shared=<1|0>] [,size=<DiskSize>]
将卷用作容器根。有关所有选项的详细说明，请参阅下文。
mp[n]: [volume=]<volume> ,mp=<Path> [,acl=<1|0>] [,backup=<1|0>]
[,mountoptions=<opt[;opt...]>] [,quota=<1|0>] [,replicate=<1|0>]
[,ro=<1|0>] [,shared=<1|0>] [,size=<DiskSize>]
将卷用作容器挂载点。使用特殊语法 STORAGE_ID:SIZE_IN_GiB 分配一个新卷。
acl=<boolean>
明确启用或禁用 ACL 支持。
backup=<boolean>
是否在备份中包含挂载点（仅用于卷挂载点）。
mountoptions=<opt[;opt...]>
rootfs/mps 的额外挂载选项。
mp=<Path>
从容器内部看到的挂载点路径。
注意
出于安全原因，不得包含任何符号链接。
quota=<boolean>
在容器内启用用户配额（不支持 zfs 子卷）
replicate=<boolean> (默认值 = 1)
将此卷包含在存储复制作业中。
ro=<boolean>
只读挂载点
shared=<boolean> (默认值 = 0)
将此非卷挂载点标记为在所有节点上可用。
警告
此选项不会自动共享挂载点，而是假定它已经共享！
size=<DiskSize>
卷大小（只读值）。
volume=<volume>
要挂载到容器中的卷、设备或目录。
目前有三种类型的挂载点：存储支持的挂载点、绑定挂载和设备挂载。
典型的容器 rootfs 配置
rootfs: thin1:base-100-disk-1,size=8G
存储支持的挂载点
存储支持的挂载点由 Proxmox VE 存储子系统管理，分为三种不同类型：
• 基于镜像：这些是包含单个 ext4 格式文件系统的原始镜像。
• ZFS 子卷：这些在技术上是绑定挂载，但具有托管存储，因此允许调整大小和快照。
• 目录：传递 size=0 触发一种特殊情况，在这种情况下，会创建一个目录，而不是原始镜像。
注意
存储支持的挂载点卷的特殊选项语法 STORAGE_ID:SIZE_IN_GB 将自动在指定的存储上分配指定大小的卷。例如，调用
pct set 100 -mp0 thin1:10,mp=/path/in/container
将在 thin1 存储上分配一个 10GB 的卷，并用分配的卷 ID 替换占位符 10，并在容器的 /path/in/container 中设置挂载点。
绑定挂载点
绑定挂载允许您在容器内访问 Proxmox VE 主机上的任意目录。一些可能的用例包括：
• 在客户机中访问主目录
• 在客户机中访问 USB 设备目录
• 在客户机中访问主机的 NFS 挂载
绑定挂载被认为不受存储子系统管理，因此您无法从容器内部进行快照或处理配额。对于非特权容器，您可能会遇到由用户映射引起的权限问题，并且无法使用 ACL。
注意
使用 vzdump 备份时，绑定挂载点的内容不会被备份。
警告
出于安全原因，绑定挂载应该只使用专门为此目的保留的源目录，例如 /mnt/bindmounts 下的目录层次结构。
切勿将系统目录（如 /, /var 或 /etc）绑定到容器中，这会带来很大的安全风险。
注意
绑定挂载源路径不能包含任何符号链接。
例如，要将目录 /mnt/bindmounts/shared 在 ID 为 100 的容器下的路径 /shared 中访问，可以添加如下配置行：
mp0: /mnt/bindmounts/shared,mp=/shared
放入 /etc/pve/lxc/100.conf。
或者使用 pct 工具：
pct set 100 -mp0 /mnt/bindmounts/shared,mp=/shared
以达到相同的效果。
设备挂载点
设备挂载点允许将主机的块设备直接挂载到容器中。与绑定挂载类似，设备挂载不受 Proxmox VE 存储子系统管理，但会遵循配额和 acl 选项。
注意
设备挂载点应仅在特殊情况下使用。在大多数情况下，存储支持的挂载点提供相同的性能和更多功能。
注意
使用 vzdump 备份时，设备挂载点的内容不会被备份。

11.4.5 网络
您可以为单个容器配置多达 10 个网络接口。相应的选项称为 net0 到 net9，它们可以包含以下设置：
net[n]: name=<string> [,bridge=<bridge>] [,firewall=<1|0>]
[,gw=<GatewayIPv4>] [,gw6=<GatewayIPv6>]
[,hwaddr=XX:XX:XX:XX:XX:XX] [,ip=<(IPv4/CIDR|dhcp|manual)>]
[,ip6=<(IPv6/CIDR|auto|dhcp|manual)>] [,link_down=<1|0>]
[,mtu=<integer>] [,rate=<mbps>] [,tag=<integer>]
[,trunks=<vlanid[;vlanid...]>] [,type=<veth>]
为容器指定网络接口。
bridge=<bridge>
将网络设备连接到的桥。
firewall=<boolean>
控制是否使用此接口的防火墙规则。
gw=<GatewayIPv4>
IPv4 流量的默认网关。
gw6=<GatewayIPv6>
IPv6 流量的默认网关。
hwaddr=XX:XX:XX:XX:XX:XX
未设置 I/G（个体/组）位的通用 MAC 地址。
ip=<(IPv4/CIDR|dhcp|manual)>
CIDR 格式的 IPv4 地址。
ip6=<(IPv6/CIDR|auto|dhcp|manual)>
CIDR 格式的 IPv6 地址。
link_down=<boolean>
此接口是否应断开连接（如拔掉插头）。
mtu=<integer> (64 - 65535)
接口的最大传输单元（lxc.network.mtu）。
name=<string>
容器内部看到的网络设备名称（lxc.network.name）。
rate=<mbps>
对接口应用速率限制
tag=<integer> (1 - 4094)
此接口的 VLAN 标签。
trunks=<vlanid[;vlanid...]>
通过接口传递的 VLAN ID
type=<veth>
网络接口类型。

11.4.6 容器的自动启动和关闭
要在主机系统启动时自动启动容器，请在 Web 界面的容器选项面板中选择“开机启动”选项，或运行以下命令：
pct set CTID -onboot 1
启动和关闭顺序
如果您想微调容器的启动顺序，可以使用以下参数：
• 启动/关闭顺序：定义启动顺序优先级。例如，如果您希望 CT 成为第一个启动的容器，请将其设置为 1。
（我们使用相反的启动顺序进行关闭，因此启动顺序为 1 的容器将是最后一个被关闭的）
• 启动延迟：定义此容器启动和后续容器启动之间的间隔。例如，如果您希望在启动其他容器之前等待 240 秒，请将其设置为 240。
• 关闭超时：定义 Proxmox VE 在发出关闭命令后应等待容器离线的秒数。
默认情况下，此值设置为 60，这意味着 Proxmox VE 将发出关闭请求，等待 60 秒，以使机器离线，如果 60 秒后机器仍然在线，则通知关闭操作失败。
请注意，没有设置启动/关闭顺序参数的容器将始终在设置了该参数的容器之后启动，而且此参数仅对本地运行在主机上的虚拟机有意义，而不是整个集群范围。
如果需要在主机启动和第一个容器启动之间有延迟，请参阅 Proxmox VE 节点管理第 3.10.4 节。

11.4.7 Hookscripts
您可以使用配置属性 hookscript 为 CT 添加一个钩子脚本。
pct set 100 -hookscript local:snippets/hookscript.pl
在客户端生命周期的各个阶段，将调用它。有关示例和文档，请参阅 /usr/share/pve-docs/examples/guest-example-hookscript.pl 下的示例脚本。

11.5 安全考虑
容器使用主机系统的内核。这为恶意用户暴露了攻击面。一般来说，完全虚拟化的机器提供更好的隔离。如果为未知或不受信任的人提供容器，应考虑这一点。
为减少攻击面，LXC 使用了许多安全功能，如 AppArmor、CGroups 和内核命名空间。

11.5.1 AppArmor
AppArmor 配置文件用于限制可能危险操作的访问。某些系统调用，即挂载操作，被禁止执行。
要追踪 AppArmor 活动，请使用：
dmesg | grep apparmor
虽然不推荐，但可以为容器禁用 AppArmor。这会带来安全风险。在容器内执行某些系统调用可能会导致权限升级，如果系统配置错误或存在 LXC 或 Linux 内核漏洞。
要为容器禁用 AppArmor，请将以下行添加到位于 /etc/pve/lxc/CTID.conf 的容器配置文件中：
lxc.apparmor.profile = unconfined
警告
请注意，这不推荐用于生产环境。

11.5.2 控制组（cgroup）
cgroup 是一种内核机制，用于层次化组织进程并分配系统资源。通过 cgroup 控制的主要资源是 CPU 时间、内存和交换限制以及对设备节点的访问。cgroup 也用于在进行快照之前 "冻结" 容器。
目前有两个版本的 cgroup 可用，分别是旧版和 cgroupv2。
从 Proxmox VE 7.0 开始，默认使用纯 cgroupv2 环境。以前使用的是 "混合" 设置，其中资源控制主要在 cgroupv1 中进行，另外还有一个 cgroupv2 控制器，
可以通过 cgroup_no_v1 内核命令行参数接管某些子系统。 （有关详细信息，请参阅内核参数文档。）
CGroup 版本兼容性
关于 Proxmox VE，纯 cgroupv2 与旧混合环境之间的主要区别是：现在，cgroupv2 
中的内存和交换空间是独立控制的。容器的内存和交换空间设置可以直接映射到这些值，而以前只能限制内存限制和内存与交换空间之和的限制。
另一个重要区别是设备控制器的配置方式完全不同。因此，纯 cgroupv2 环境中目前不支持文件系统配额。
容器的操作系统需要支持 cgroupv2，才能在纯 cgroupv2 环境中运行。运行 systemd 版本 231 或更高版本的容器支持 cgroupv2 1，不使用 systemd 作为 init 系统的容器也支持 2。
注意
CentOS 7 和 Ubuntu 16.10 是两个著名的 Linux 发行版，它们的 systemd 版本太旧，无法在 cgroupv2 环境中运行，您可以选择：
• 将整个发行版升级到更新的版本。对于上述示例，可以选择 Ubuntu 18.04 或 20.04，以及 CentOS 8（或 RHEL/CentOS 衍生版，如 AlmaLinux 或 Rocky 
Linux）。这样可以获得最新的错误修复和安全修复，通常还有新功能，并将 EOL 日期延长到未来。
• 升级容器的 systemd 版本。如果发行版提供了一个 backports 存储库，这可能是一种简便快捷的临时解决方案。
• 将容器或其服务移到虚拟机中。虚拟机与主机的交互要少得多，这就是为什么在虚拟机中可以很好地安装几十年前的操作系统版本。
• 切换回旧版 cgroup 控制器。请注意，虽然这可能是一个有效的解决方案，但它不是一个永久性的解决方案。
很有可能在未来的 Proxmox VE 主要版本（例如 8.0）中，将不再支持旧版控制器。
1 这包括 Proxmox VE 提供的所有最新主要版本的容器模板
2 例如 Alpine Linux
更改 CGroup 版本
提示
如果不需要文件系统配额并且所有容器都支持 cgroupv2，建议坚持使用新的默认设置。
要切换回上一个版本，可以使用以下内核命令行参数：
systemd.unified_cgroup_hierarchy=0
有关在何处添加参数的详细信息，请参阅本节第 3.12.6 节，了解如何编辑内核启动命令行。

11.6 客户操作系统配置
Proxmox VE 尝试检测容器中的 Linux 发行版，并修改一些文件。以下是容器启动时执行的操作的简短列表：
设置 /etc/hostname
以设置容器名称
修改 /etc/hosts
以允许查找本地主机名
网络设置
将完整的网络设置传递给容器
配置 DNS
传递有关 DNS 服务器的信息
调整 init 系统
例如，修复生成的 getty 进程数量
设置 root 密码
在创建新容器时
重写 ssh_host_keys
使每个容器都具有唯一的密钥
随机化 crontab
使得 cron 不会在所有容器上同时启动
Proxmox VE 所做的更改由注释标记括起来：
# --- BEGIN PVE ---
<data>
# --- END PVE ---
这些标记将被插入到文件的合理位置。如果已经存在这样的部分，它将在原地更新，不会被移动。
通过为文件添加一个 .pve-ignore 文件可以防止修改文件。例如，如果文件 /etc/.pve-ignore.hosts 存在，那么 /etc/hosts 
文件将不会被更改。这可以是通过以下命令创建的一个简单的空文件：
touch /etc/.pve-ignore.hosts
大多数修改是依赖于操作系统的，因此它们在不同的发行版和版本之间有所不同。您可以通过手动将 ostype 设置为 unmanaged 来完全禁用修改。
通过检测容器内的某些文件来进行操作系统类型检测。Proxmox VE 首先检查 /etc/os-release 文件 
3。如果该文件不存在，或者不包含一个明显可识别的发行版标识符，将检查以下特定发行版的发行文件。
Ubuntu
检查 /etc/lsb-release（DISTRIB_ID=Ubuntu）
Debian
测试 /etc/debian_version
Fedora
测试 /etc/fedora-release
RedHat 或 CentOS
测试 /etc/redhat-release
ArchLinux
测试 /etc/arch-release
Alpine
测试 /etc/alpine-release
Gentoo
测试 /etc/gentoo-release
注意
如果配置的 ostype 与自动检测到的类型不同，容器启动将失败。

11.7 容器存储
Proxmox VE LXC 容器存储模型比传统的容器存储模型更具灵活性。一个容器可以有多个挂载点。这使得可以为每个应用程序使用最适合的存储。
3 /etc/os-release 取代了每个发行版的众多发行文件 https://manpages.debian.org/stable/systemd/os-release.5.en.html
例如，容器的根文件系统可以位于慢速且便宜的存储上，而数据库可以通过第二个挂载点位于快速且分布式的存储上。有关详细信息，请参阅挂载点部分。
可以使用 Proxmox VE 存储库支持的任何存储类型。这意味着容器可以存储在本地（例如 lvm，zfs 或目录），共享的外部（如 iSCSI，NFS）甚至是像 Ceph 
这样的分布式存储系统上。如果底层存储支持，可以使用诸如快照或克隆之类的高级存储功能。vzdump 备份工具可以使用快照来提供一致的容器备份。
此外，可以使用绑定挂载直接挂载本地设备或本地目录。这使得可以在容器内以实际上零开销访问本地资源。绑定挂载可以用作一种在容器之间共享数据的简便方法。

11.7.1 FUSE 挂载
警告
由于 Linux 内核的 freezer 子系统中存在的问题，强烈建议不要在容器内使用 FUSE 挂载，因为容器需要被冻结以进行挂起或快照模式备份。
如果无法用其他挂载机制或存储技术替换 FUSE 挂载，则可以在 Proxmox 主机上建立 FUSE 挂载，并使用绑定挂载点使其在容器内部可访问。

11.7.2 在容器内使用配额
配额允许在容器内为每个用户可以使用的磁盘空间量设置限制。
注意
这目前需要使用传统的 cgroups。
注意
这仅适用于基于 ext4 图像的存储类型，并且目前仅适用于特权容器。
激活配额选项会导致挂载点使用以下挂载选项：usrjquota=aquota。这使得配额可以像在任何其他系统上一样使用。
您可以通过运行以下命令初始化 /aquota.user 和 /aquota.group 文件：
quotacheck -cmug /
quotaon /
然后使用 edquota 命令编辑配额。有关在容器内运行的发行版的详细信息，请参阅文档。
注意
您需要为每个挂载点运行上述命令，方法是传递挂载点的路径，而不仅仅是 /。

11.7.3 在容器内使用 ACL
标准的 Posix 访问控制列表也可以在容器内使用。ACL 允许您设置比传统的用户/组/其他模型更详细的文件所有权。

11.7.4 容器挂载点的备份
要在备份中包含挂载点，请在容器配置中为其启用备份选项。对于现有的挂载点 mp0：
mp0: guests:subvol-100-disk-1,mp=/root/files,size=8G
添加 backup=1 以启用它。
mp0: guests:subvol-100-disk-1,mp=/root/files,size=8G,backup=1
注意
在 GUI 中创建新挂载点时，默认情况下启用此选项。
要禁用挂载点的备份，在上述方式中添加 backup=0，或取消选中 GUI 上的备份复选框。

11.7.5 容器挂载点的复制
默认情况下，在根磁盘被复制时，额外的挂载点也会被复制。如果您希望 Proxmox VE 存储复制机制跳过某个挂载点，
可以为该挂载点设置跳过复制选项。从 Proxmox VE 5.0 开始，复制需要 zfspool 类型的存储。当容器配置了复制时，将挂载点添加到不同类型的存储需要为该挂载点启用跳过复制。

11.8 备份和恢复
11.8.1 容器备份
可以使用 vzdump 工具进行容器备份。请参阅 vzdump 手册页以获取详细信息。

11.8.2 恢复容器备份
使用 pct restore 命令可以恢复使用 vzdump 制作的容器备份。默认情况下，pct restore 
将尝试尽可能多地恢复已备份的容器配置。可以通过在命令行上手动设置容器选项来覆盖已备份的配置（有关详细信息，请参阅 pct 手册页）。
注意
pvesm extractconfig 可用于查看 vzdump 存档中包含的已备份配置。
有两种基本的恢复模式，仅在处理挂载点方面有所不同：
“简单”恢复模式
如果未显式设置 rootfs 参数和任何可选的 mpX 参数，则使用以下步骤恢复备份配置文件中的挂载点配置：
    从备份中提取挂载点及其选项
    在使用 storage 参数（默认值：local）提供的存储上为存储支持的挂载点创建卷。
    从备份存档中提取文件
    将绑定和设备挂载点添加到恢复的配置（仅限 root 用户）
    注意
    由于绑定和设备挂载点从不备份，因此在最后一步不会还原任何文件，而只会还原配置选项。
    假设这样的挂载点要么使用另一种机制备份（例如，绑定到多个容器中的 NFS 空间），要么根本不打算备份。
    此简单模式还用于 Web 界面中的容器还原操作。
    “高级”恢复模式
    通过设置 rootfs 参数（以及可选地，任意组合 mpX 参数），pct restore 命令自动切换到高级模式。
    此高级模式完全忽略备份存档中包含的 rootfs 和 mpX 配置选项，而仅使用作为参数显式提供的选项。
    此模式允许在恢复时灵活配置挂载点设置，例如：
    • 分别为每个挂载点设置目标存储、卷大小和其他选项
    • 根据新的挂载点方案重新分配备份的文件
    • 还原到设备和/或绑定挂载点（仅限 root 用户）
    
11.9 使用 pct 管理容器
    “Proxmox 容器工具包”（pct）是用于管理 Proxmox VE 
    容器的命令行工具。它允许您创建或销毁容器，以及控制容器执行（启动、停止、重启、迁移等）。它可用于设置容器配置文件中的参数，例如网络配置或内存限制。

11.9.1 命令行使用示例
基于 Debian 模板创建一个容器（前提是您已通过 Web 界面下载了模板）
pct create 100 /var/lib/vz/template/cache/debian-10.0-standard_10.0-1_amd64.tar.gz
启动容器 100
pct start 100
通过 getty 启动登录会话
pct console 100
进入 LXC 命名空间并以 root 用户身份运行 shell
pct enter 100
显示配置
pct config 100
添加名为 eth0 的网络接口，桥接到主机桥接器 vmbr0，设置地址和网关，同时运行
pct set 100 -net0 name=eth0,bridge=vmbr0,ip=192.168.15.147/24,gw=192.168.15.1
将容器的内存减少到 512MB
pct set 100 -memory 512
销毁容器始终会将其从访问控制列表中删除，而且始终会删除容器的防火墙配置。如果要额外将容器从复制作业、备份作业和 HA 资源配置中删除，您需要激活 --purge。
pct destroy 100 --purge
将挂载点卷移动到其他存储。
pct move-volume 100 mp0 other-storage
将卷重新分配给不同的 CT。这将从源 CT 中删除卷 mp0 并将其作为 mp1 附加到目标 CT。在后台，卷将被重命名以使名称与新所有者匹配。
# pct move-volume 100 mp0 --target-vmid 200 --target-volume mp1

11.9.2 获取调试日志
如果 pct start 无法启动特定容器，通过传递 --debug 标志收集调试输出可能会有所帮助（将 CTID 替换为容器的 CTID）：
pct start CTID --debug
或者，您可以使用以下 lxc-start 命令，该命令将将调试日志保存到由 -o 输出选项指定的文件中：
lxc-start -n CTID -F -l DEBUG -o /tmp/lxc-CTID.log
此命令将尝试在前台模式下启动容器，要停止容器，请在第二个终端中运行 pct shutdown CTID 或 pct stop CTID。
收集到的调试日志将写入 /tmp/lxc-CTID.log。
注意
如果自上次使用 pct start 尝试启动容器以来，您已更改了容器的配置，则需要至少运行一次 pct start 以更新 lxc-start 使用的配置。

11.10 迁移
如果您有一个集群，您可以使用以下命令迁移容器：
pct migrate <ctid> <target>
只要您的容器处于离线状态，这就可以工作。如果容器具有定义的本地卷或挂载点，迁移将通过网络将内容复制到目标主机（如果目标主机上定义了相同的存储）。
由于技术限制，运行中的容器无法进行实时迁移。您可以执行重新启动迁移，它将关闭容器，在目标节点上重新启动并启动容器。
由于容器非常轻量级，这通常只会导致几百毫秒的停机时间。
可以通过 Web 界面执行重新启动迁移，也可以通过将 --restart 标志与 pct 迁移命令一起使用。
重新启动迁移将关闭容器，并在指定的超时时间后终止容器（默认为 180 秒）。然后，它将像离线迁移一样迁移容器，完成后，在目标节点上启动容器。

11.11 配置
/etc/pve/lxc/<CTID>.conf 文件存储容器配置，其中 <CTID> 是给定容器的数字 ID。与 /etc/pve/ 内存储的所有其他文件一样，它们会自动复制到所有其他集群节点。
注意
CTIDs < 100 保留用于内部目的，CTIDs 需要在整个集群范围内具有唯一性。
示例容器配置
ostype: debian
arch: amd64
hostname: www
memory: 512
swap: 512
net0: bridge=vmbr0,hwaddr=66:64:66:64:64:36,ip=dhcp,name=eth0,type=veth
rootfs: local:107/vm-107-disk-1.raw,size=7G
配置文件是简单的文本文件。您可以使用普通的文本编辑器（例如 vi 或 nano）对它们进行编辑。这有时对于进行小的更正很有用，但请记住，您需要重新启动容器以应用此类更改。
出于这个原因，通常最好使用 pct 命令生成和修改这些文件，或者使用 GUI 
完成整个操作。我们的工具箱足够智能，可以立即将大多数更改应用于正在运行的容器。这个功能被称为“热插拔”，在这种情况下不需要重新启动容器。
在无法进行热插拔更改的情况下，它将被注册为待处理更改（在 GUI 中以红色显示）。它们只有在重新启动容器后才会被应用。

11.11.1 文件格式
容器配置文件使用简单的冒号分隔的键/值格式。每行具有以下格式：
＃这是一条评论
OPTION: value
这些文件中的空行将被忽略，以＃字符开头的行将被视为注释并被忽略。
可以直接添加低级别的 LXC 样式配置，例如：
lxc.init_cmd: /sbin/my_own_init
或者
lxc.init_cmd = /sbin/my_own_init
这些设置直接传递给 LXC 低级工具。

11.11.2 快照
当您创建快照时，pct 将在同一配置文件中的单独快照部分中存储快照时间的配置。例如，在创建名为“testsnapshot”的快照后，您的配置文件将如下所示：
带有快照的容器配置
memory: 512
swap: 512
parent: testsnaphot
...
[testsnaphot]
memory: 512
swap: 512
snaptime: 1457170803
...
有一些与快照相关的属性，如 parent 和 snaptime。parent 属性用于存储快照之间的父/子关系。snaptime 是快照创建时间戳（Unix 纪元）。

11.11.3 选项
arch: <amd64 | arm64 | armhf | i386 | riscv32 | riscv64> (默认 = amd64)
操作系统架构类型。
cmode: <console | shell | tty> (默认 = tty)
控制台模式。默认情况下，控制台命令尝试打开与可用 tty 设备之一的连接。将 cmode 设置为控制台后，它将尝试连接到 /dev/console。
如果将 cmode 设置为 shell，它只会在容器内调用一个 shell（无需登录）。
console: <boolean> (默认 = 1)
将控制台设备（/dev/console）连接到容器。
cores: <integer> (1 - 8192)
分配给容器的内核数。默认情况下，容器可以使用所有可用的内核。
cpulimit: <number> (0 - 8192) (默认 = 0)
CPU 使用限制。
注意
如果计算机有 2 个 CPU，那么它总共有 2 个 CPU 时间。值 0 表示没有 CPU 限制。
cpuunits: <integer> (0 - 500000) (默认 = cgroup v1: 1024, cgroup v2: 100)
容器的 CPU 权重。参数用于内核公平调度程序。数字越大，容器获得的 CPU 时间越多。数字与所有其他正在运行的客户机的权重相对。

























































